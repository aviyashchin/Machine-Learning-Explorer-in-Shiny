#cast things properly - NUMERIC VS INTEGERS?   REALLY R PEOPLE?
Fruits_Vegetables[,1]=as.integer(Fruits_Vegetables[,1])
Scumbags[,1]=as.integer(Scumbags[,1])
AllScumbags[,13]=as.integer(AllScumbags[,13])
NumCompanies[,"first_q_payroll"]=as.integer(NumCompanies[,"first_q_payroll"])
NumCompanies[,"annual_payroll"]=as.integer(NumCompanies[,"annual_payroll"])
NumCompanies[,"num_paid_employees"]=as.integer(NumCompanies[,"num_paid_employees"])
PovertyEstimates[,"FIPS"]=as.integer(as.data.frame(PovertyEstimates)[,"FIPS"])
allscumbags[,"FIPS"]=as.integer(as.data.frame(allscumbags)[,"FIPS"])
Fruits_Vegetables[,"FIPS"]=as.integer(as.data.frame(Fruits_Vegetables)[,"FIPS"])
SocialCapital[,"FIPS"]=as.integer(as.data.frame(SocialCapital)[,"FIPS"])
#fix ZiptoFips Index
ZiptoFips[,"ZCTA5"]=as.character(ZiptoFips[,"ZCTA5"])
Zeyu=left_join(ZiptoFips,AllScumbags,by="ZCTA5")
Zeyu[,"FIPS"]=as.character(Zeyu[,"FIPS"])
Zeyu[,"FIPS"]=as.integer(Zeyu[,"FIPS"])
Zeyu = Zeyu[!is.na(Zeyu[, "SBs"]),]
Zeyu <- tbl_df(Zeyu)
allscumbags <- group_by(Zeyu, FIPS) %>% summarize(s=sum(SBs))
names(allscumbags)[names(allscumbags)=="s"] <- "SBs"
names(allscumbags)[names(allscumbags)=="as.factor(FIPS)"] <- "FIPS"
#remove NA's
#	Scumbags=Scumbags[complete.cases(Scumbags[,1]),]
AllScumbags=AllScumbags[complete.cases(AllScumbags[,13]),]
Fruits_Vegetables=Fruits_Vegetables[complete.cases(Fruits_Vegetables[,1]),]
allData=list(Bankruptcy, Fruits_Vegetables, SocialCapital, Unemployment, Disparity, Education, No_Exercise, NumCompanies, PovertyEstimates, PopulationEstimates,allscumbags)
i=1
FIPS=Bankruptcy
#  	FIPS=left_join(FIPS,allData[[i]],by="FIPS")
for (i in 2:length(allData)){
print(paste("table ",i," ",nrow(allData[[i]])))
FIPS=left_join(FIPS,allData[[i]],by="FIPS")
print(paste("rows:",nrow(FIPS)))
}
influencePlot(model.saturated)
vif(model.saturated) #Assessing the variance inflation factors for the variables
avPlots(model.saturated) #Distinct patterns are indications of good contributions
model2 = lm(Life.Exp ~ . - Illiteracy, data = states)
summary(model2) #R^2 adjusted went up, model still significant, etc.
plot(model2) #No overt additional violations.
vif(model2) #VIFs all decrease.
anova(model2, model.saturated) #The p-value is quite large, indicating that we
model2 = lm(Life.Exp ~ . - Illiteracy, data = states)
summary(model2) #R^2 adjusted went up, model still significant, etc.
plot(model2) #No overt additional violations.
summary(model2) #R^2 adjusted went up, model still significant, etc.
model2 = lm(Life.Exp ~ . - Illiteracy, data = states)
summary(model2) #R^2 adjusted went up, model still significant, etc.
plot(model2) #No overt additional violations.
vif(model2) #VIFs all decrease.
anova(model2, model.saturated) #The p-value is quite large, indicating that we
anova(model2, model.saturated) #The p-value is quite large, indicating that we
model2 = lm(Life.Exp ~ . - Illiteracy, data = states)
summary(model2) #R^2 adjusted went up, model still significant, etc.
plot(model2) #No overt additional violations.
influencePlot(model2) #No overt additional violations; Hawaii actually lowers
vif(model2) #VIFs all decrease.
anova(model2, model.saturated) #The p-value is quite large, indicating that we
model.full = lm(Life.Exp ~ ., data = states)
model.reduced = lm(Life.Exp ~ . - Illiteracy - Area - Income, data = states)
anova(model.reduced, model.full) #The p-value is quite large; thus, the reduced
summary(model.reduced)
plot(model.reduced)
vif(model.reduced)
AIC(model.full,    #Model with all variables.
model2,        #Model with all variables EXCEPT Illiteracy.
model.reduced) #Model with all variables EXCEPT Illiteracy, Area, and Income.
library(cats)
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
library(cats)
?mass
?MASS
CATS
cats
library(MASS)
cats
c<- cats
ggplot(mpg, aes(hwy, cty)) +
geom_point(aes(color = cyl)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_bw()
library(ggplot2)
ggplot2(â€)
ggplot2()
library("ggplot2")
ggplot(mpg, aes(hwy, cty)) +
geom_point(aes(color = cyl)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_bw()
View(cats)
ggplot(cats, aes(Btw, Hwt)) +
geom_point(aes(color = Sex)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_bw()
ggplot(cats, aes(Bwt, Hwt)) +
geom_point(aes(color = Sex)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_bw()
ggplot(cats, aes(Bwt, Hwt)) +
#  geom_point(aes(color = Sex)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_bw()
ggplot(cats, aes(cats$Bwt, cats$Hwt)) +
#  geom_point(aes(color = Sex)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_bw()
ggplot(cats, aes(cats$Bwt, cats$Hwt)) +
#  geom_point(aes(color = Sex)) +
#  geom_smooth(method ="lm") +
#  coord_cartesian() +
#  scale_color_gradient() +
theme_bw()
plot()
plot(model)
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)   # Add linear regression line
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)   # Add linear regression line
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)   # Add linear regression line
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
scale_color_gradient() +
theme_bw()
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_bw()
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian()
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
?theme_hc
??theme_hc
library(ggthemes)
??theme_hc
?theme_hc
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
ylab("Homeless Rate Change (percentage points)") +
xlab("Mental Health Budget Change (percentage points)")+
ggtitle("State Homeless Rate Change by MH Budget Change, 2009-2013")
cats$Bwt
label(cats)
colnames(cats)
x=cats$Bwt
colname(x)
colnames(x)
x
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
ggplot(mpg, aes(hwy, cty)) +
geom_point(aes(color = cyl)) +
geom_smooth(method ="lm") +
coord_cartesian() +
scale_color_gradient() +
theme_hc()
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
ggplot(cats, aes(x=cats$Hwt, y=cats$Bwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
?lm
lm(cats$Bwt ~ cats$Hwt))
lm(cats$Bwt ~ cats$Hwt)
lm(cats$Hwt ~ cats$Bwt)
lm(cats$Bwt ~ cats$Hwt)
lm(cats ~ .)
sapply(cars, sd) #Standard deviations.
cor(cars) #Correlations.
hist(cars$speed, xlab = "Speed in MPH", main = "Histogram of Speed")
hist(cars$dist, xlab = "Distance in Feet", main = "Histogram of Distance")
hist(cars$dist, xlab = "Distance in Feet", main = "Histogram of Distance")
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2)
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
abline(beta0, beta1, lty = 2)
lm(cats$Bwt ~ cats$Hwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
beta1
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
lm(cats$Bwt ~ cats$Hwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
residuals
abline(beta0, beta1, lty = 2)
ggline(beta0, beta1, lty = 2)
gg_line(beta0, beta1, lty = 2)
geom_line(beta0, beta1, lty = 2)
line(beta0, beta1, lty = 2)
line(beta0, beta1, lty = 2)
abline(beta0, beta1, lty = 2)
residuals = cars$dist - (beta0 + beta1*cats$Bwt)
beta1
beta0
colnames(cats)
?cats
lm(cats$Bwt ~ cats$Hwt)
summary(lm(cats$Bwt ~ cats$Hwt))
sum(residuals)
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
summary(lm(cats$Bwt ~ cats$Hwt))
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(beta0, beta1, lty = 2)
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
#conduct the simple linear regression.
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
summary(model) #All the summary information for the model in question. Reports:
t.statistic = 9.464
f.statistic = 89.57
t.statistic^2
confint(model) #Creating 95% confidence intervals for the model coefficients.
summary(model)
model = lm(cats$Bwt ~ cats$Hwt)
summary(model)
confint(model)
summary(model)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cars$dist - mean(cars$dist))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cars$dist) - beta1*mean(cats$Bwt)
beta1
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
beta1
beta0
residuals
hist(cats$Hwt, xlab = "Heart Weight in G", main = "Histogram of HW")
hist(cats$Bwt, xlab = "Body Weight in KG", main = "Histogram of BW")
hist(cats$Hwt, xlab = "Heart Weight in G", main = "Histogram of HW")
hist(cats$Bwt, xlab = "Body Weight in KG", main = "Histogram of BW")
plot(cats)
lm(cats$Hwt ~ cats$Bwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
plot(cats)
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
plot(x=cats$Hwt, y=cats$Bwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
plot(x=cats$Hwt, y=cats$Bwt)
abline(beta0, beta1, lty = 2)
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
segments(cats, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
segments(cats, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
segments(cats, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
beta1
abline(beta0, beta1, lty = 2)
plot(x=cats$Hwt, y=cats$Bwt)
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
beta1 = sum((cars$speed - mean(cars$speed)) * (cars$dist - mean(cars$dist))) /
sum((cars$speed - mean(cars$speed))^2)
beta0 = mean(cars$dist) - beta1*mean(cars$speed)
abline(beta0, beta1, lty = 2)
plot(x=cats$Bwt, y=cats$Hwt)
abline(beta0, beta1, lty = 2)
abline(beta0, beta1, lty = 2)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /
sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
abline(beta0, beta1, lty = 2)
abline(beta0, beta1, lty = 2)
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
residuals
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
summary(model)
plot(x=cats$Bwt, y=cats$Hwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
lm(cats$Hwt ~ cats$Bwt)
plot(x=cats$Bwt, y=cats$Hwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = cats$Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
summary(model)
confint(model)
sum(residuals)
sum(residuals)
c<- cats
# 1. Create a scatterplot of heart weight versus body weight. From this plot alone, do you think simple linear regression would be a good fit for the data? Why?
ggplot(cats, aes(x=cats$Hwt, y=cats$Bwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
hist(cats$Hwt, xlab = "Heart Weight in G", main = "Histogram of HW")
hist(cats$Bwt, xlab = "Body Weight in KG", main = "Histogram of BW")
plot(cats)
lm(cats$Hwt ~ cats$Bwt)
#yes, because they're in a straight line more or les
# 2. Regress heart weight onto body weight. For this model:
# a. Write out the regression equation.
plot(x=cats$Bwt, y=cats$Hwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
# b. Interpret the meaning of the coefficients in context of the problem.
#beta1 is around 4, so for every increase in 1kg of bodyweight you get a 4x increase of heart weight (in g).
#Beta0, the intercempt is 0.3, so a cat weighing -lbs will have a negative heart weight. (that was a joke)
# c. Are the coefficients significant? How can you tell?
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = cats$Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
model = lm(cats$Bwt ~ cats$Hwt)
# d. Is the overall regression significant? How can you tell? How does the answer to part c. relate?
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
summary(model)
segments(cars$speed, cars$dist,
cars$speed, (beta0 + beta1*cars$speed),
col = "red")
text(cars$speed - .5, cars$dist, round(residuals, 2), cex = 0.5)
model = lm(dist ~ speed, data = cars) #Use the linear model function lm() to
summary(model) #All the summary information for the model in question. Reports:
t.statistic = 9.464
f.statistic = 89.57
t.statistic^2
confint(model) #Creating 95% confidence intervals for the model coefficients.
plot(cars, xlab = "Speed in MPH", ylab = "Distance in Feet",
main = "Scatterplot of Cars Dataset")
abline(model, lty = 2)
#Constant Variance & Independent Errors
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
abline(h = 0, lty = 2)
c<- cats
# 1. Create a scatterplot of heart weight versus body weight. From this plot alone, do you think simple linear regression would be a good fit for the data? Why?
ggplot(cats, aes(x=cats$Hwt, y=cats$Bwt)) +
geom_point(aes(color = Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
hist(cats$Hwt, xlab = "Heart Weight in G", main = "Histogram of HW")
hist(cats$Bwt, xlab = "Body Weight in KG", main = "Histogram of BW")
plot(cats)
lm(cats$Hwt ~ cats$Bwt)
#yes, because they're in a straight line more or les
# 2. Regress heart weight onto body weight. For this model:
# a. Write out the regression equation.
plot(x=cats$Bwt, y=cats$Hwt)
beta1 = sum((cats$Bwt - mean(cats$Bwt)) * (cats$Hwt - mean(cats$Hwt))) /sum((cats$Bwt - mean(cats$Bwt))^2)
beta0 = mean(cats$Hwt) - beta1*mean(cats$Bwt)
abline(beta0, beta1, lty = 2)
# b. Interpret the meaning of the coefficients in context of the problem.
#beta1 is around 4, so for every increase in 1kg of bodyweight you get a 4x increase of heart weight (in g).
#Beta0, the intercempt is 0.3, so a cat weighing -lbs will have a negative heart weight. (that was a joke)
# c. Are the coefficients significant? How can you tell?
ggplot(cats, aes(x=cats$Bwt, y=cats$Hwt)) +
geom_point(aes(color = cats$Sex)) +
geom_point(shape=1) +    # Use hollow circles
geom_smooth(method=lm)+   # Add linear regression line
coord_cartesian() +
theme_hc()
model = lm(cats$Bwt ~ cats$Hwt)
# d. Is the overall regression significant? How can you tell? How does the answer to part c. relate?
residuals = cats$Hwt - (beta0 + beta1*cats$Bwt)
segments(cats$Bwt, cats$Hwt,
cats$Bwt, (beta0 + beta1*cats$Bwt),
col = "red")
text(cats$Hwt - .5, cars$dist, round(residuals, 2), cex = 0.5)
summary(model)
#Yes, overall
# e. Find and interpret the RSE.
sum(residuals)
sum(residuals)
plot(model$fitted, model$residuals,
xlab = "Fitted Values", ylab = "Residual Values",
main = "Residual Plot for Cars Dataset")
abline(h = 0, lty = 2)
qqnorm(model$residuals)
qqline(model$residuals)
plot(model) #Note the addition of the loess smoother and scale-location plot
qqnorm(model$residuals)
qqline(model$residuals)
plot(model) #Note the addition of the loess smoother and scale-location plot
par(mfrow=c(2,2)) #2x2 plot
plot(model) #Note the addition of the loess smoother and scale-location plot
confint(model)
